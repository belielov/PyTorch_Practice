{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0953d7c1-1f20-4814-a12a-0003ae24874a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' 线性回归的简洁实现 '"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" 线性回归的简洁实现 \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f9d5c71-b884-4e23-acb2-a75dca9a8a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 通过使用深度学习框架来简洁地实现 线性回归模型 生成数据集\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils import data\n",
    "from d2l import torch as d2l\n",
    "\n",
    "true_w = torch.tensor([2, -3.4])\n",
    "true_b = 4.2\n",
    "features, labels = d2l.synthetic_data(true_w, true_b, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18dee32e-8065-48de-9098-53b5dba35049",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[-0.2650,  0.5514],\n",
       "         [-0.5000, -1.0541],\n",
       "         [ 1.7470, -0.5217],\n",
       "         [ 2.7687, -0.4720],\n",
       "         [-0.7131,  0.4301],\n",
       "         [ 0.9517,  0.3629],\n",
       "         [-1.2120,  1.8238],\n",
       "         [ 1.8306, -1.4740],\n",
       "         [ 0.0329,  0.8826],\n",
       "         [-0.2995,  1.6272]]),\n",
       " tensor([[ 1.7933],\n",
       "         [ 6.8012],\n",
       "         [ 9.4629],\n",
       "         [11.3368],\n",
       "         [ 1.3220],\n",
       "         [ 4.8610],\n",
       "         [-4.4370],\n",
       "         [12.8669],\n",
       "         [ 1.2570],\n",
       "         [-1.9507]])]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 调用框架中现有的 API 来读取数据\n",
    "def load_array(data_arrays, batch_size, is_train=True):\n",
    "    \"\"\" \n",
    "    构造一个 PyTorch 数据迭代器 \n",
    "    :param data_arrays: 包含特征和标签的元组（如 (features, labels)）\n",
    "    :param batch_size: 每个批次的样本数量\n",
    "    :param is_train: 是否为训练模式（决定是否打乱数据顺序）\n",
    "    :return: PyTorch 数据加载器对象\n",
    "    \"\"\"\n",
    "    \n",
    "    # 将特征和标签组合成 PyTorch 数据集对象\n",
    "    # *data_arrays 解包元组，例如将 (features, labels) 解为 features, labels\n",
    "    dataset = data.TensorDataset(*data_arrays)\n",
    "    \n",
    "    # 创建数据加载器，按批次加载数据\n",
    "    # shuffle=is_train：训练时打乱数据顺序，验证/测试时保持顺序\n",
    "    return data.DataLoader(dataset, batch_size, shuffle=is_train)\n",
    "\n",
    "batch_size = 10\n",
    "data_iter = load_array((features, labels), batch_size)\n",
    "\n",
    "# 获取数据迭代器的第一个批次数据\n",
    "# iter(data_iter) 创建迭代器，next() 获取下一个批次\n",
    "next(iter(data_iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72e3c91c-b275-4771-ad6a-ea847ea29957",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用框架的预定义好的层\n",
    "# `nn`是神经网络的缩写\n",
    "from torch import nn\n",
    "\n",
    "net = nn.Sequential(nn.Linear(2, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f584783-a8e8-49e4-ae51-4d68128dd95e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 初始化模型参数\n",
    "net[0].weight.data.normal_(0, 0.01)  # net[0] 表示访问 nn.Sequential 容器中的 第一个层\n",
    "net[0].bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a20fd08-4cac-4513-91ff-aa091fb24935",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算均方误差使用的是MSELoss类\n",
    "loss = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4572317a-c2df-4a1d-844a-ed0754f7dfb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 实例化 SGD 实例\n",
    "trainer = torch.optim.SGD(net.parameters(), lr=0.03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f7a4c677-9d7d-438a-8197-5dd1ffa6b011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss 0.000092\n",
      "epoch 2, loss 0.000091\n",
      "epoch 3, loss 0.000092\n"
     ]
    }
   ],
   "source": [
    "# 训练过程\n",
    "num_epochs = 3  # 定义训练的总轮数（完整遍历数据集的次数）\n",
    "for epoch in range(num_epochs):\n",
    "    # 内层循环：逐批次遍历训练数据\n",
    "    for X, y in data_iter:\n",
    "        # 前向传播：计算当前批次的预测值与真实值的损失\n",
    "        l = loss(net(X), y)\n",
    "        \n",
    "        # 梯度清零：清除优化器中上一次迭代的梯度，避免梯度累积\n",
    "        trainer.zero_grad()\n",
    "        \n",
    "        # 反向传播：根据损失计算模型参数的梯度\n",
    "        l.backward()\n",
    "        \n",
    "        # 参数更新：根据梯度使用优化器（SGD）更新模型参数\n",
    "        trainer.step()\n",
    "    \n",
    "    # 每轮训练结束后，计算整个数据集上的损失\n",
    "    # 注意：此处使用全部数据（features, labels）而非小批量，用于评估模型整体性能\n",
    "    l = loss(net(features), labels)\n",
    "    \n",
    "    # 打印当前轮数和总损失值\n",
    "    print(f'epoch {epoch + 1}, loss {l:f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
