{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e057a33-af53-4966-828d-fc50869c7023",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d661d101-eb1d-492b-9be9-bb38535106bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 张量表示一个数值组成的数组,这个数组可能有多个纬度\n",
    "x = torch.arange(12)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5dfd4890-2193-4639-8a80-3d641875a134",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 我们可以通过张量的shape属性来访问张量的形状和张量中元素的总数\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ababe6be-c29d-4243-bed6-3b75cf03c11c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 元素总数\n",
    "x.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9bdd59b3-f1f3-47ae-9843-5bf7ab8f697f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2,  3],\n",
       "        [ 4,  5,  6,  7],\n",
       "        [ 8,  9, 10, 11]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 要改变一个张量的形状而不改变元素数量和元素值,我们可以调用 reshape 函数\n",
    "x = x.reshape(3, 4)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1ad4c29b-2fb7-4670-b3b4-fe7c5dca4b69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用全0,全1,其他常量或者从特定分布中随机采样的数字\n",
    "\"\"\"\n",
    "在PyTorch中，张量的形状是从最外层到最内层排列的。\n",
    "比如，形状(2,3,4)意味着第一个维度有2个元素，每个元素是一个3x4的矩阵；\n",
    "第二个维度有3个元素，每个是长度为4的向量；\n",
    "第三个维度是每个向量中的4个元素。\n",
    "\"\"\"\n",
    "torch.zeros((2, 3, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "acf48f62-759d-4ebf-9f5f-73d45142ed3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones((2, 3, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "578e463e-67e7-4737-9a07-143c6aa841f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 通过提供包含数值的python列表(或嵌套列表)来为所需张量中的每个元素赋以确定值\n",
    "torch.tensor(\n",
    "    [[2, 1, 4, 3],\n",
    "    [1, 2, 3, 4],\n",
    "    [4, 3, 2, 1]]\n",
    ").shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "04dce5cf-8a5c-48b2-a68e-d67eb3ced34f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 3.,  4.,  6., 10.]),\n",
       " tensor([-1.,  0.,  2.,  6.]),\n",
       " tensor([ 2.,  4.,  8., 16.]),\n",
       " tensor([ 1.,  4., 16., 64.]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 常见的标准算术运算符(+, -, *, / 和 **)都可以被升级为按元素运算\n",
    "x = torch.tensor([1.0, 2, 4, 8])\n",
    "y = torch.tensor([2, 2, 2, 2])\n",
    "x + y, x - y, x * y, x ** y  # **运算符是求幂运算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "46395e68-c5e8-46a7-a89d-ef0478483886",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.7183e+00, 7.3891e+00, 5.4598e+01, 2.9810e+03])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.exp(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8305eb06-1e3e-4134-ac5c-0d708bd9f7b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.,  1.,  2.,  3.],\n",
       "         [ 4.,  5.,  6.,  7.],\n",
       "         [ 8.,  9., 10., 11.],\n",
       "         [ 2.,  1.,  4.,  3.],\n",
       "         [ 1.,  2.,  3.,  4.],\n",
       "         [ 4.,  3.,  2.,  1.]]),\n",
       " tensor([[ 0.,  1.,  2.,  3.,  2.,  1.,  4.,  3.],\n",
       "         [ 4.,  5.,  6.,  7.,  1.,  2.,  3.,  4.],\n",
       "         [ 8.,  9., 10., 11.,  4.,  3.,  2.,  1.]]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 合并张量\n",
    "X = torch.arange(12, dtype=torch.float32).reshape(3, 4)\n",
    "Y = torch.tensor([[2.0, 1, 4, 3], [1, 2, 3, 4], [4, 3, 2, 1]])\n",
    "# 分别在第0维和第1维合并,即按行和按列合并\n",
    "torch.cat((X, Y), dim=0), torch.cat((X, Y), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9e826ed7-2c51-4c5e-9432-fc1b1fe44d5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False,  True, False,  True],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 通过逻辑运算符构建二维张量\n",
    "X == Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5d296fc4-14e4-4a62-9af9-f1a433e04f88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(66.)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 对张量中的所有元素进行求和会产生一个只有一个元素的张量\n",
    "X.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0b920265-6c71-40b9-8588-aaab5e850930",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0],\n",
       "         [1],\n",
       "         [2]]),\n",
       " tensor([[0, 1]]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 即使形状不同,我们仍然可以通过调用广播机制(broadcasting mechanism)来执行按元素操作\n",
    "a = torch.arange(3).reshape((3, 1))\n",
    "b = torch.arange(2).reshape((1, 2))\n",
    "a, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ce243246-6582-44ce-873b-df967a760a33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1],\n",
       "        [1, 2],\n",
       "        [2, 3]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "在广播机制下，a 和 b分别扩展为：\n",
    "[[0, 0],\n",
    " [1, 1],\n",
    " [2, 2]]\n",
    "\n",
    "[[0, 1],\n",
    " [0, 1],\n",
    " [0, 1]] \n",
    "\"\"\"\n",
    "a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f3b5a995-d382-44b2-bbe1-e50e8ec07aaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 8.,  9., 10., 11.]),\n",
       " tensor([[ 4.,  5.,  6.,  7.],\n",
       "         [ 8.,  9., 10., 11.]]))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" 元素访问\n",
    "可以用[-1]选择最后一个元素,\n",
    "可以用[1:3]选择第二个和第三个元素\n",
    "\"\"\"\n",
    "X[-1], X[1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "88c49e72-3300-49e8-9f8f-600528d09d89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  1.,  2.,  3.],\n",
       "        [ 4.,  5.,  9.,  7.],\n",
       "        [ 8.,  9., 10., 11.]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 除读取外,我们还可以通过指定索引来将元素写入矩阵\n",
    "X[1, 2] = 9\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6299d010-0b90-461d-96bd-da642fc5baa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[12., 12., 12., 12.],\n",
       "        [12., 12., 12., 12.],\n",
       "        [ 8.,  9., 10., 11.]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 为多个元素赋相同的值,只需要索引所有元素,然后为它们赋值\n",
    "X[0:2, :] = 12\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "90cd57f9-88e4-4d9f-b5e5-1c87149cc5da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 运行一些操作可能会导致为新结果分配内存\n",
    "before = id(Y)\n",
    "Y = Y + X\n",
    "id(Y) == before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "84acb1f1-d1a1-449b-8f50-25c5bb1aeb2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id(Z): 2446309287000\n",
      "id(Z): 2446309287000\n"
     ]
    }
   ],
   "source": [
    "Z = torch.zeros_like(Y)  # 继承Y的type和shape,但元素均为1\n",
    "print('id(Z):', id(Z))\n",
    "Z[:] = X + Y\n",
    "print('id(Z):', id(Z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5d13fc39-a20a-41c7-abc7-abe81debfeab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 如果在后续计算中没有重复使用X,我们也可以使用 X[:] = X + Y or X += Y 来减少操作的内存开销\n",
    "before = id(X)\n",
    "X += Y\n",
    "id(X) == before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5c10f91e-3d30-4143-94c7-141b494fb8ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, torch.Tensor)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 转换为 Numpy 张量\n",
    "A = X.numpy()\n",
    "B = torch.tensor(A)\n",
    "type(A), type(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "888db6b7-1f08-47a9-bce2-ec2cd32fd30c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([3.5000]), 3.5, 3.5, 3)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 将大小为1的张量转换为 python 标量\n",
    "a = torch.tensor([3.5])\n",
    "a, a.item(), float(a), int(a)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
