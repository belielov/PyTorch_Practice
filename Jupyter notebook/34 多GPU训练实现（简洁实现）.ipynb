{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf12d8c-eca4-4a8d-ace7-92a8ac1eeede",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496efaf9-4ba6-4045-af45-65152180a525",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 简单网络\n",
    "def resnet18(num_classess, in_channels=1):\n",
    "    def resnet_block(in_channels, out_channels, num_residuals, first_block=False):\n",
    "        blk = []\n",
    "        for i in range(num_residuals):\n",
    "            if i == 0 and not first_block:\n",
    "                blk.append(d2l.Residual(in_channels, out_channels, use_1x1conv=True, strides=2))\n",
    "            else:\n",
    "                blk.append(d2l.Residual(out_channels, out_channels))\n",
    "        return nn.Sequential(*blk)\n",
    "\n",
    "    net = nn.Sequential(\n",
    "        nn.Conv2d(in_channels, 64, kernel_size=3, stride=1, padding=1),\n",
    "        nn.BatchNorm2d(64), nn.ReLU())\n",
    "    net.add_module('resnet_block1', resnet_block(64, 64, 2, first_block=True))\n",
    "    net.add_module('resnet_block2', resnet_block(64, 128, 2))\n",
    "    net.add_module('resnet_block3', resnet_block(128, 256, 2))\n",
    "    net.add_module('resnet_block4', resnet_block(256, 512, 2))\n",
    "    net.add_module('global_avg_pool', nn.AdaptiveAvgPool2d((1, 1)))\n",
    "    net.add_module('fc', nn.Sequential(nn.Flatten(), nn.Linear(512, num_classes)))\n",
    "    return net\n",
    "\n",
    "net = resnet18(10)\n",
    "devices = d2l.try_all_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c84fcb-2cb8-454e-a4d9-f5ad1c36fcb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练\n",
    "def train(net, num_gpus, batch_size, lr):\n",
    "    train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size)\n",
    "    devices = [d2l.try_gpu(i) for i in range(num_gpus)]\n",
    "\n",
    "    def init_weights(m):\n",
    "        if type(m) in [nn.Linear, nn.Conv2d]:\n",
    "            nn.init.normal_(m.weight, std=0.01)\n",
    "\n",
    "    net.apply(init_weights)\n",
    "    net = nn.DataParallel(net, device_ids=devices)\n",
    "    trainer = torch.optim.SGD(net.parameters(), lr)\n",
    "    loss = nn.CrossEntropyLoss()\n",
    "    timer, num_epochs = d2l.Timer(), 10\n",
    "    animator = d2l.Animator('epoch', 'test acc', xlim=[1, num_epochs])\n",
    "    for epoch in range(num_epochs):\n",
    "        net.train()\n",
    "        timer.start()\n",
    "        for X, y in train_iter:\n",
    "            trainer.zero_grad()\n",
    "            X, y = X.to(devices[0]), y.to(devices[0])\n",
    "            l = loss(net(X), y)\n",
    "            l.backward()\n",
    "            trainer.step()\n",
    "        timer.stop()\n",
    "        animator.add(epoch+1, (d2l.evaluate_accuracy_gpu(net, test_iter)))\n",
    "    print(f'test acc: {animator.Y[0][-1]:.2f}, {timer.avg():.1f} sec/epoch'\n",
    "         f' on {str(devices)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be29b45-97b6-4246-92bd-c4acbd6bc4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在单个GPU上训练网络\n",
    "train(net, num_gpus=1, batch_size=256, lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18777ff-b984-4fae-9724-99a0dd899294",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用2个GPU进行训练\n",
    "train(net, num_gpus=2, batch_size=512, lr=0.2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
